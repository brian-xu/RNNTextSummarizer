{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920f7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = \"Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413201fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ever',\n",
       " 'noticed',\n",
       " 'how',\n",
       " 'plane',\n",
       " 'seats',\n",
       " 'appear',\n",
       " 'to',\n",
       " 'be',\n",
       " 'getting',\n",
       " 'smaller',\n",
       " 'and',\n",
       " 'smaller?',\n",
       " 'With',\n",
       " 'increasing',\n",
       " 'numbers',\n",
       " 'of',\n",
       " 'people',\n",
       " 'taking',\n",
       " 'to',\n",
       " 'the',\n",
       " 'skies,',\n",
       " 'some',\n",
       " 'experts',\n",
       " 'are',\n",
       " 'questioning',\n",
       " 'if',\n",
       " 'having',\n",
       " 'such',\n",
       " 'packed',\n",
       " 'out',\n",
       " 'planes',\n",
       " 'is',\n",
       " 'putting',\n",
       " 'passengers',\n",
       " 'at',\n",
       " 'risk.',\n",
       " 'They',\n",
       " 'say',\n",
       " 'that',\n",
       " 'the',\n",
       " 'shrinking',\n",
       " 'space',\n",
       " 'on',\n",
       " 'aeroplanes',\n",
       " 'is',\n",
       " 'not',\n",
       " 'only',\n",
       " 'uncomfortable',\n",
       " '-',\n",
       " \"it's\",\n",
       " 'putting',\n",
       " 'our',\n",
       " 'health',\n",
       " 'and',\n",
       " 'safety',\n",
       " 'in',\n",
       " 'danger.',\n",
       " 'More',\n",
       " 'than',\n",
       " 'squabbling',\n",
       " 'over',\n",
       " 'the',\n",
       " 'arm',\n",
       " 'rest,',\n",
       " 'shrinking',\n",
       " 'space',\n",
       " 'on',\n",
       " 'planes',\n",
       " 'putting',\n",
       " 'our',\n",
       " 'health',\n",
       " 'and',\n",
       " 'safety',\n",
       " 'in',\n",
       " 'danger?',\n",
       " 'This',\n",
       " 'week,',\n",
       " 'a',\n",
       " 'U.S',\n",
       " 'consumer',\n",
       " 'advisory',\n",
       " 'group',\n",
       " 'set',\n",
       " 'up',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Department',\n",
       " 'of',\n",
       " 'Transportation',\n",
       " 'said',\n",
       " 'at',\n",
       " 'a',\n",
       " 'public',\n",
       " 'hearing',\n",
       " 'that',\n",
       " 'while',\n",
       " 'the',\n",
       " 'government',\n",
       " 'is',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'set',\n",
       " 'standards',\n",
       " 'for',\n",
       " 'animals',\n",
       " 'flying',\n",
       " 'on',\n",
       " 'planes,',\n",
       " 'it',\n",
       " \"doesn't\",\n",
       " 'stipulate',\n",
       " 'a',\n",
       " 'minimum',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'space',\n",
       " 'for',\n",
       " 'humans.',\n",
       " \"'In\",\n",
       " 'a',\n",
       " 'world',\n",
       " 'where',\n",
       " 'animals',\n",
       " 'have',\n",
       " 'more',\n",
       " 'rights',\n",
       " 'to',\n",
       " 'space',\n",
       " 'and',\n",
       " 'food',\n",
       " 'than',\n",
       " \"humans,'\",\n",
       " 'said',\n",
       " 'Charlie',\n",
       " 'Leocha,',\n",
       " 'consumer',\n",
       " 'representative',\n",
       " 'on',\n",
       " 'the',\n",
       " 'committee.Â',\n",
       " \"'It\",\n",
       " 'is',\n",
       " 'time',\n",
       " 'that',\n",
       " 'the',\n",
       " 'DOT',\n",
       " 'and',\n",
       " 'FAA',\n",
       " 'take',\n",
       " 'a',\n",
       " 'stand',\n",
       " 'for',\n",
       " 'humane',\n",
       " 'treatment',\n",
       " 'of',\n",
       " \"passengers.'\",\n",
       " 'But',\n",
       " 'could',\n",
       " 'crowding',\n",
       " 'on',\n",
       " 'planes',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'more',\n",
       " 'serious',\n",
       " 'issues',\n",
       " 'than',\n",
       " 'fighting',\n",
       " 'for',\n",
       " 'space',\n",
       " 'in',\n",
       " 'the',\n",
       " 'overhead',\n",
       " 'lockers,',\n",
       " 'crashing',\n",
       " 'elbows',\n",
       " 'and',\n",
       " 'seat',\n",
       " 'back',\n",
       " 'kicking?',\n",
       " 'Tests',\n",
       " 'conducted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'FAA',\n",
       " 'use',\n",
       " 'planes',\n",
       " 'with',\n",
       " 'a',\n",
       " '31',\n",
       " 'inch',\n",
       " 'pitch,',\n",
       " 'a',\n",
       " 'standard',\n",
       " 'which',\n",
       " 'on',\n",
       " 'some',\n",
       " 'airlines',\n",
       " 'has',\n",
       " 'decreased',\n",
       " '.',\n",
       " 'Many',\n",
       " 'economy',\n",
       " 'seats',\n",
       " 'on',\n",
       " 'United',\n",
       " 'Airlines',\n",
       " 'have',\n",
       " '30',\n",
       " 'inches',\n",
       " 'of',\n",
       " 'room,',\n",
       " 'while',\n",
       " 'some',\n",
       " 'airlines',\n",
       " 'offer',\n",
       " 'as',\n",
       " 'little',\n",
       " 'as',\n",
       " '28',\n",
       " 'inches',\n",
       " '.',\n",
       " 'Cynthia',\n",
       " 'Corbertt,',\n",
       " 'a',\n",
       " 'human',\n",
       " 'factors',\n",
       " 'researcher',\n",
       " 'with',\n",
       " 'the',\n",
       " 'Federal',\n",
       " 'Aviation',\n",
       " 'Administration,',\n",
       " 'that',\n",
       " 'it',\n",
       " 'conducts',\n",
       " 'tests',\n",
       " 'on',\n",
       " 'how',\n",
       " 'quickly',\n",
       " 'passengers',\n",
       " 'can',\n",
       " 'leave',\n",
       " 'a',\n",
       " 'plane.',\n",
       " 'But',\n",
       " 'these',\n",
       " 'tests',\n",
       " 'are',\n",
       " 'conducted',\n",
       " 'using',\n",
       " 'planes',\n",
       " 'with',\n",
       " '31',\n",
       " 'inches',\n",
       " 'between',\n",
       " 'each',\n",
       " 'row',\n",
       " 'of',\n",
       " 'seats,',\n",
       " 'a',\n",
       " 'standard',\n",
       " 'which',\n",
       " 'on',\n",
       " 'some',\n",
       " 'airlines',\n",
       " 'has',\n",
       " 'decreased,',\n",
       " 'reported',\n",
       " 'the',\n",
       " 'Detroit',\n",
       " 'News.',\n",
       " 'The',\n",
       " 'distance',\n",
       " 'between',\n",
       " 'two',\n",
       " 'seats',\n",
       " 'from',\n",
       " 'one',\n",
       " 'point',\n",
       " 'on',\n",
       " 'a',\n",
       " 'seat',\n",
       " 'to',\n",
       " 'the',\n",
       " 'same',\n",
       " 'point',\n",
       " 'on',\n",
       " 'the',\n",
       " 'seat',\n",
       " 'behind',\n",
       " 'it',\n",
       " 'is',\n",
       " 'known',\n",
       " 'as',\n",
       " 'the',\n",
       " 'pitch.',\n",
       " 'While',\n",
       " 'most',\n",
       " 'airlines',\n",
       " 'stick',\n",
       " 'to',\n",
       " 'a',\n",
       " 'pitch',\n",
       " 'of',\n",
       " '31',\n",
       " 'inches',\n",
       " 'or',\n",
       " 'above,',\n",
       " 'some',\n",
       " 'fall',\n",
       " 'below',\n",
       " 'this.',\n",
       " 'While',\n",
       " 'United',\n",
       " 'Airlines',\n",
       " 'has',\n",
       " '30',\n",
       " 'inches',\n",
       " 'of',\n",
       " 'space,',\n",
       " 'Gulf',\n",
       " 'Air',\n",
       " 'economy',\n",
       " 'seats',\n",
       " 'have',\n",
       " 'between',\n",
       " '29',\n",
       " 'and',\n",
       " '32',\n",
       " 'inches,',\n",
       " 'Air',\n",
       " 'Asia',\n",
       " 'offers',\n",
       " '29',\n",
       " 'inches',\n",
       " 'and',\n",
       " 'Spirit',\n",
       " 'Airlines',\n",
       " 'offers',\n",
       " 'just',\n",
       " '28',\n",
       " 'inches.',\n",
       " 'British',\n",
       " 'Airways',\n",
       " 'has',\n",
       " 'a',\n",
       " 'seat',\n",
       " 'pitch',\n",
       " 'of',\n",
       " '31',\n",
       " 'inches,',\n",
       " 'while',\n",
       " 'easyJet',\n",
       " 'has',\n",
       " '29',\n",
       " 'inches,',\n",
       " \"Thomson's\",\n",
       " 'short',\n",
       " 'haul',\n",
       " 'seat',\n",
       " 'pitch',\n",
       " 'is',\n",
       " '28',\n",
       " 'inches,',\n",
       " 'and',\n",
       " 'Virgin',\n",
       " \"Atlantic's\",\n",
       " 'is',\n",
       " '30-31.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = final_text.split()\n",
    "lowercase_words = []\n",
    "for word in text:\n",
    "    lowercase_words.append(word)\n",
    "lowercase_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554cbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264f60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34791427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ever</td>\n",
       "      <td>ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noticed</td>\n",
       "      <td>notic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane</td>\n",
       "      <td>plane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seats</td>\n",
       "      <td>seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Virgin</td>\n",
       "      <td>virgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Atlantic's</td>\n",
       "      <td>atlantic'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>30-31.</td>\n",
       "      <td>30-31.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_word stemmed_word\n",
       "0          Ever         ever\n",
       "1       noticed        notic\n",
       "2           how          how\n",
       "3         plane        plane\n",
       "4         seats         seat\n",
       "..          ...          ...\n",
       "365         and          and\n",
       "366      Virgin       virgin\n",
       "367  Atlantic's    atlantic'\n",
       "368          is           is\n",
       "369      30-31.       30-31.\n",
       "\n",
       "[370 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = final_text.split()\n",
    "stemmed_words = [porter_stemmer.stem(word = word) for word in words]\n",
    "\n",
    "stemmed_table= pd.DataFrame({'orig_word': words,'stemmed_word': stemmed_words})\n",
    "stemmed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f53b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83a053ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\19496\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c393fdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_word</th>\n",
       "      <th>lemmatized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ever</td>\n",
       "      <td>Ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noticed</td>\n",
       "      <td>notice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane</td>\n",
       "      <td>plane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seats</td>\n",
       "      <td>seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Virgin</td>\n",
       "      <td>Virgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Atlantic's</td>\n",
       "      <td>Atlantic's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>30-31.</td>\n",
       "      <td>30-31.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_word lemmatized_word\n",
       "0          Ever            Ever\n",
       "1       noticed          notice\n",
       "2           how             how\n",
       "3         plane           plane\n",
       "4         seats            seat\n",
       "..          ...             ...\n",
       "365         and             and\n",
       "366      Virgin          Virgin\n",
       "367  Atlantic's      Atlantic's\n",
       "368          is              be\n",
       "369      30-31.          30-31.\n",
       "\n",
       "[370 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = final_text.split()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word=word,pos='v') for word in words]\n",
    "lemmatized_table = pd.DataFrame({'orig_word': words,'lemmatized_word': lemmatized_words})\n",
    "lemmatized_table = lemmatized_table[['orig_word','lemmatized_word']]\n",
    "lemmatized_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7e5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10afde05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13700/3922961496.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTOP_WORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cada4be1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP_WORDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13700/1895245673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOP_WORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'STOP_WORDS' is not defined"
     ]
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194cfc59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13700/2925551115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mchosen_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "words = final_text.split()\n",
    "chosen_words = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopwords:\n",
    "        chosen_words.append(w)\n",
    "    else:\n",
    "        chosen_words.append(\"W\")\n",
    "\n",
    "print(\"orig sentence = \",final_text)    \n",
    "print(\"sentence with stop words removed = \",' '.join(shortlisted_words))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235c7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ff4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "056f229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ever</td>\n",
       "      <td>ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noticed</td>\n",
       "      <td>notic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane</td>\n",
       "      <td>plane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seats</td>\n",
       "      <td>seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Virgin</td>\n",
       "      <td>virgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Atlantic's</td>\n",
       "      <td>atlantic'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>30-31.</td>\n",
       "      <td>30-31.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_word stemmed_word\n",
       "0          Ever         ever\n",
       "1       noticed        notic\n",
       "2           how          how\n",
       "3         plane        plane\n",
       "4         seats         seat\n",
       "..          ...          ...\n",
       "365         and          and\n",
       "366      Virgin       virgin\n",
       "367  Atlantic's    atlantic'\n",
       "368          is           is\n",
       "369      30-31.       30-31.\n",
       "\n",
       "[370 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_words = final_text.split()\n",
    "stemmed_words = [porter_stemmer.stem(word=word) for word in orig_words]\n",
    "stemmed_table = pd.DataFrame({'orig_word': orig_words,'stemmed_word': stemmed_words})\n",
    "stemmed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4982c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_words(text):\n",
    "    text = re.sub(\"(<.*?>)\",\"\",text)\n",
    "    \n",
    "    text = re.sub(\"(\\\\W|\\\\d)\",\" \",text)\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b4eb82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_word</th>\n",
       "      <th>cleaned_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ever</td>\n",
       "      <td>Ever</td>\n",
       "      <td>ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noticed</td>\n",
       "      <td>noticed</td>\n",
       "      <td>notic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane</td>\n",
       "      <td>plane</td>\n",
       "      <td>plane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seats</td>\n",
       "      <td>seats</td>\n",
       "      <td>seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Virgin</td>\n",
       "      <td>Virgin</td>\n",
       "      <td>virgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Atlantic's</td>\n",
       "      <td>Atlantic s</td>\n",
       "      <td>atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>30-31.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_word cleaned_word stemmed_word\n",
       "0          Ever         Ever         ever\n",
       "1       noticed      noticed        notic\n",
       "2           how          how          how\n",
       "3         plane        plane        plane\n",
       "4         seats        seats         seat\n",
       "..          ...          ...          ...\n",
       "365         and          and          and\n",
       "366      Virgin       Virgin       virgin\n",
       "367  Atlantic's   Atlantic s    atlantic \n",
       "368          is           is           is\n",
       "369      30-31.                          \n",
       "\n",
       "[370 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words = []\n",
    "for word in orig_words:\n",
    "    clean_words.append(scrub_words(word))\n",
    "\n",
    "clean_stemmed_words=[porter_stemmer.stem(word=word) for word in clean_words]\n",
    "stemmed_table= pd.DataFrame({'orig_word': orig_words,'cleaned_word':clean_words,'stemmed_word': clean_stemmed_words})\n",
    "stemmed_table=stemmed_table[['orig_word','cleaned_word','stemmed_word']]\n",
    "stemmed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
